{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/towardsai/ragbook-notebooks/blob/main/notebooks/Chapter%2005%20-%20LlamaIndex_Introduction.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "9gRt2BXzwASv"
      },
      "outputs": [],
      "source": [
        "!pip install -q llama-index==0.9.14.post3 deeplake==3.8.8 cohere==4.37"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 47,
      "metadata": {
        "id": "tjwZjA8-wITr"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "import sys\n",
        "\n",
        "#You can set the logging level to DEBUG for more verbose output,\n",
        "# or use level=logging.INFO for less detailed information.\n",
        "logging.basicConfig(stream=sys.stdout, level=logging.DEBUG)\n",
        "logging.getLogger().addHandler(logging.StreamHandler(stream=sys.stdout))"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PLUDcXpI41Q_"
      },
      "source": [
        "# LlamaHub Wikipedia Integration"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 48,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MhaDzVaxwIRD",
        "outputId": "fc9cb5c0-c1b3-4641-c37c-77a93ff5eba9"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): llamahub.ai:443\n",
            "Starting new HTTPS connection (1): llamahub.ai:443\n",
            "Starting new HTTPS connection (1): llamahub.ai:443\n",
            "Starting new HTTPS connection (1): llamahub.ai:443\n",
            "Starting new HTTPS connection (1): llamahub.ai:443\n",
            "Starting new HTTPS connection (1): llamahub.ai:443\n",
            "DEBUG:urllib3.connectionpool:https://llamahub.ai:443 \"POST /api/analytics/downloads HTTP/1.1\" 200 63\n",
            "https://llamahub.ai:443 \"POST /api/analytics/downloads HTTP/1.1\" 200 63\n",
            "https://llamahub.ai:443 \"POST /api/analytics/downloads HTTP/1.1\" 200 63\n",
            "https://llamahub.ai:443 \"POST /api/analytics/downloads HTTP/1.1\" 200 63\n",
            "https://llamahub.ai:443 \"POST /api/analytics/downloads HTTP/1.1\" 200 63\n",
            "https://llamahub.ai:443 \"POST /api/analytics/downloads HTTP/1.1\" 200 63\n"
          ]
        }
      ],
      "source": [
        "from llama_index import download_loader\n",
        "\n",
        "WikipediaReader = download_loader(\"WikipediaReader\")\n",
        "\n",
        "loader = WikipediaReader()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 49,
      "metadata": {
        "id": "Z35ot7P1wIO0"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "DEBUG:urllib3.connectionpool:http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Natural+Language+Processing&srinfo=suggestion&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Natural+Language+Processing&srinfo=suggestion&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Natural+Language+Processing&srinfo=suggestion&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Natural+Language+Processing&srinfo=suggestion&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Natural+Language+Processing&srinfo=suggestion&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Natural+Language+Processing&srinfo=suggestion&format=json&action=query HTTP/1.1\" 301 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "DEBUG:urllib3.connectionpool:https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Natural+Language+Processing&srinfo=suggestion&format=json&action=query HTTP/1.1\" 200 174\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Natural+Language+Processing&srinfo=suggestion&format=json&action=query HTTP/1.1\" 200 174\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Natural+Language+Processing&srinfo=suggestion&format=json&action=query HTTP/1.1\" 200 174\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Natural+Language+Processing&srinfo=suggestion&format=json&action=query HTTP/1.1\" 200 174\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Natural+Language+Processing&srinfo=suggestion&format=json&action=query HTTP/1.1\" 200 174\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Natural+Language+Processing&srinfo=suggestion&format=json&action=query HTTP/1.1\" 200 174\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "DEBUG:urllib3.connectionpool:http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 301 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "DEBUG:urllib3.connectionpool:https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 200 278\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 200 278\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 200 278\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 200 278\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 200 278\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 200 278\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "DEBUG:urllib3.connectionpool:http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 301 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "DEBUG:urllib3.connectionpool:https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 200 None\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 200 None\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 200 None\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 200 None\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 200 None\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Natural+language+processing&format=json&action=query HTTP/1.1\" 200 None\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "DEBUG:urllib3.connectionpool:http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Artificial+Intelligence&srinfo=suggestion&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Artificial+Intelligence&srinfo=suggestion&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Artificial+Intelligence&srinfo=suggestion&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Artificial+Intelligence&srinfo=suggestion&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Artificial+Intelligence&srinfo=suggestion&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Artificial+Intelligence&srinfo=suggestion&format=json&action=query HTTP/1.1\" 301 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "DEBUG:urllib3.connectionpool:https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Artificial+Intelligence&srinfo=suggestion&format=json&action=query HTTP/1.1\" 200 172\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Artificial+Intelligence&srinfo=suggestion&format=json&action=query HTTP/1.1\" 200 172\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Artificial+Intelligence&srinfo=suggestion&format=json&action=query HTTP/1.1\" 200 172\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Artificial+Intelligence&srinfo=suggestion&format=json&action=query HTTP/1.1\" 200 172\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Artificial+Intelligence&srinfo=suggestion&format=json&action=query HTTP/1.1\" 200 172\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?list=search&srprop=&srlimit=1&limit=1&srsearch=Artificial+Intelligence&srinfo=suggestion&format=json&action=query HTTP/1.1\" 200 172\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "DEBUG:urllib3.connectionpool:http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 301 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "DEBUG:urllib3.connectionpool:https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 200 276\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 200 276\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 200 276\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 200 276\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 200 276\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=info%7Cpageprops&inprop=url&ppprop=disambiguation&redirects=&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 200 276\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "Starting new HTTP connection (1): en.wikipedia.org:80\n",
            "DEBUG:urllib3.connectionpool:http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 301 0\n",
            "http://en.wikipedia.org:80 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 301 0\n",
            "DEBUG:urllib3.connectionpool:Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "Starting new HTTPS connection (1): en.wikipedia.org:443\n",
            "DEBUG:urllib3.connectionpool:https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 200 None\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 200 None\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 200 None\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 200 None\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 200 None\n",
            "https://en.wikipedia.org:443 \"GET /w/api.php?prop=extracts%7Crevisions&explaintext=&rvprop=ids&titles=Artificial+intelligence&format=json&action=query HTTP/1.1\" 200 None\n"
          ]
        }
      ],
      "source": [
        "documents = loader.load_data(pages=['Natural Language Processing', 'Artificial Intelligence'])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 50,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0i9Zp6BJwILk",
        "outputId": "f7ade60f-631a-4b51-981a-26fda4f7c4a6"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "2"
            ]
          },
          "execution_count": 50,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "len( documents )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qkKPAnIl44ss"
      },
      "source": [
        "# Create Nodes"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 51,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: Natural language processing (NLP) is a subfield...\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "> Adding chunk: Natural language processing (NLP) is a subfield...\n",
            "> Adding chunk: Natural language processing (NLP) is a subfield...\n",
            "> Adding chunk: Natural language processing (NLP) is a subfield...\n",
            "> Adding chunk: Natural language processing (NLP) is a subfield...\n",
            "> Adding chunk: Natural language processing (NLP) is a subfield...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: When the \"patient\" exceeded the very small know...\n",
            "> Adding chunk: When the \"patient\" exceeded the very small know...\n",
            "> Adding chunk: When the \"patient\" exceeded the very small know...\n",
            "> Adding chunk: When the \"patient\" exceeded the very small know...\n",
            "> Adding chunk: When the \"patient\" exceeded the very small know...\n",
            "> Adding chunk: When the \"patient\" exceeded the very small know...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Statistical NLP (1990s–2010s) ===\n",
            "Up until ...\n",
            "> Adding chunk: === Statistical NLP (1990s–2010s) ===\n",
            "Up until ...\n",
            "> Adding chunk: === Statistical NLP (1990s–2010s) ===\n",
            "Up until ...\n",
            "> Adding chunk: === Statistical NLP (1990s–2010s) ===\n",
            "Up until ...\n",
            "> Adding chunk: === Statistical NLP (1990s–2010s) ===\n",
            "Up until ...\n",
            "> Adding chunk: === Statistical NLP (1990s–2010s) ===\n",
            "Up until ...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Neural NLP (present) ===\n",
            "In 2003, word n-gr...\n",
            "> Adding chunk: === Neural NLP (present) ===\n",
            "In 2003, word n-gr...\n",
            "> Adding chunk: === Neural NLP (present) ===\n",
            "In 2003, word n-gr...\n",
            "> Adding chunk: === Neural NLP (present) ===\n",
            "In 2003, word n-gr...\n",
            "> Adding chunk: === Neural NLP (present) ===\n",
            "In 2003, word n-gr...\n",
            "> Adding chunk: === Neural NLP (present) ===\n",
            "In 2003, word n-gr...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: == Approaches: Symbolic, statistical, neural ne...\n",
            "> Adding chunk: == Approaches: Symbolic, statistical, neural ne...\n",
            "> Adding chunk: == Approaches: Symbolic, statistical, neural ne...\n",
            "> Adding chunk: == Approaches: Symbolic, statistical, neural ne...\n",
            "> Adding chunk: == Approaches: Symbolic, statistical, neural ne...\n",
            "> Adding chunk: == Approaches: Symbolic, statistical, neural ne...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Neural networks ===\n",
            "\n",
            "A major drawback of st...\n",
            "> Adding chunk: === Neural networks ===\n",
            "\n",
            "A major drawback of st...\n",
            "> Adding chunk: === Neural networks ===\n",
            "\n",
            "A major drawback of st...\n",
            "> Adding chunk: === Neural networks ===\n",
            "\n",
            "A major drawback of st...\n",
            "> Adding chunk: === Neural networks ===\n",
            "\n",
            "A major drawback of st...\n",
            "> Adding chunk: === Neural networks ===\n",
            "\n",
            "A major drawback of st...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Text and speech processing ===\n",
            "Optical char...\n",
            "> Adding chunk: === Text and speech processing ===\n",
            "Optical char...\n",
            "> Adding chunk: === Text and speech processing ===\n",
            "Optical char...\n",
            "> Adding chunk: === Text and speech processing ===\n",
            "Optical char...\n",
            "> Adding chunk: === Text and speech processing ===\n",
            "Optical char...\n",
            "> Adding chunk: === Text and speech processing ===\n",
            "Optical char...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Morphological analysis ===\n",
            "Lemmatization\n",
            "Th...\n",
            "> Adding chunk: === Morphological analysis ===\n",
            "Lemmatization\n",
            "Th...\n",
            "> Adding chunk: === Morphological analysis ===\n",
            "Lemmatization\n",
            "Th...\n",
            "> Adding chunk: === Morphological analysis ===\n",
            "Lemmatization\n",
            "Th...\n",
            "> Adding chunk: === Morphological analysis ===\n",
            "Lemmatization\n",
            "Th...\n",
            "> Adding chunk: === Morphological analysis ===\n",
            "Lemmatization\n",
            "Th...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Syntactic analysis ===\n",
            "\n",
            "Grammar induction\n",
            "G...\n",
            "> Adding chunk: === Syntactic analysis ===\n",
            "\n",
            "Grammar induction\n",
            "G...\n",
            "> Adding chunk: === Syntactic analysis ===\n",
            "\n",
            "Grammar induction\n",
            "G...\n",
            "> Adding chunk: === Syntactic analysis ===\n",
            "\n",
            "Grammar induction\n",
            "G...\n",
            "> Adding chunk: === Syntactic analysis ===\n",
            "\n",
            "Grammar induction\n",
            "G...\n",
            "> Adding chunk: === Syntactic analysis ===\n",
            "\n",
            "Grammar induction\n",
            "G...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Lexical semantics (of individual words in c...\n",
            "> Adding chunk: === Lexical semantics (of individual words in c...\n",
            "> Adding chunk: === Lexical semantics (of individual words in c...\n",
            "> Adding chunk: === Lexical semantics (of individual words in c...\n",
            "> Adding chunk: === Lexical semantics (of individual words in c...\n",
            "> Adding chunk: === Lexical semantics (of individual words in c...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Relational semantics (semantics of individu...\n",
            "> Adding chunk: === Relational semantics (semantics of individu...\n",
            "> Adding chunk: === Relational semantics (semantics of individu...\n",
            "> Adding chunk: === Relational semantics (semantics of individu...\n",
            "> Adding chunk: === Relational semantics (semantics of individu...\n",
            "> Adding chunk: === Relational semantics (semantics of individu...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Discourse (semantics beyond individual sent...\n",
            "> Adding chunk: === Discourse (semantics beyond individual sent...\n",
            "> Adding chunk: === Discourse (semantics beyond individual sent...\n",
            "> Adding chunk: === Discourse (semantics beyond individual sent...\n",
            "> Adding chunk: === Discourse (semantics beyond individual sent...\n",
            "> Adding chunk: === Discourse (semantics beyond individual sent...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Higher-level NLP applications ===\n",
            "Automatic...\n",
            "> Adding chunk: === Higher-level NLP applications ===\n",
            "Automatic...\n",
            "> Adding chunk: === Higher-level NLP applications ===\n",
            "Automatic...\n",
            "> Adding chunk: === Higher-level NLP applications ===\n",
            "Automatic...\n",
            "> Adding chunk: === Higher-level NLP applications ===\n",
            "Automatic...\n",
            "> Adding chunk: === Higher-level NLP applications ===\n",
            "Automatic...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: The first published work by a neural network wa...\n",
            "> Adding chunk: The first published work by a neural network wa...\n",
            "> Adding chunk: The first published work by a neural network wa...\n",
            "> Adding chunk: The first published work by a neural network wa...\n",
            "> Adding chunk: The first published work by a neural network wa...\n",
            "> Adding chunk: The first published work by a neural network wa...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: Text-to-video\n",
            "Given a description of a video, g...\n",
            "> Adding chunk: Text-to-video\n",
            "Given a description of a video, g...\n",
            "> Adding chunk: Text-to-video\n",
            "Given a description of a video, g...\n",
            "> Adding chunk: Text-to-video\n",
            "Given a description of a video, g...\n",
            "> Adding chunk: Text-to-video\n",
            "Given a description of a video, g...\n",
            "> Adding chunk: Text-to-video\n",
            "Given a description of a video, g...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: As an example, George Lakoff offers a methodolo...\n",
            "> Adding chunk: As an example, George Lakoff offers a methodolo...\n",
            "> Adding chunk: As an example, George Lakoff offers a methodolo...\n",
            "> Adding chunk: As an example, George Lakoff offers a methodolo...\n",
            "> Adding chunk: As an example, George Lakoff offers a methodolo...\n",
            "> Adding chunk: As an example, George Lakoff offers a methodolo...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: The mathematical equation for such algorithms i...\n",
            "> Adding chunk: The mathematical equation for such algorithms i...\n",
            "> Adding chunk: The mathematical equation for such algorithms i...\n",
            "> Adding chunk: The mathematical equation for such algorithms i...\n",
            "> Adding chunk: The mathematical equation for such algorithms i...\n",
            "> Adding chunk: The mathematical equation for such algorithms i...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: Nevertheless, approaches to develop cognitive m...\n",
            "> Adding chunk: Nevertheless, approaches to develop cognitive m...\n",
            "> Adding chunk: Nevertheless, approaches to develop cognitive m...\n",
            "> Adding chunk: Nevertheless, approaches to develop cognitive m...\n",
            "> Adding chunk: Nevertheless, approaches to develop cognitive m...\n",
            "> Adding chunk: Nevertheless, approaches to develop cognitive m...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: Artificial intelligence (AI), in its broadest s...\n",
            "> Adding chunk: Artificial intelligence (AI), in its broadest s...\n",
            "> Adding chunk: Artificial intelligence (AI), in its broadest s...\n",
            "> Adding chunk: Artificial intelligence (AI), in its broadest s...\n",
            "> Adding chunk: Artificial intelligence (AI), in its broadest s...\n",
            "> Adding chunk: Artificial intelligence (AI), in its broadest s...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: == Goals ==\n",
            "The general problem of simulating (...\n",
            "> Adding chunk: == Goals ==\n",
            "The general problem of simulating (...\n",
            "> Adding chunk: == Goals ==\n",
            "The general problem of simulating (...\n",
            "> Adding chunk: == Goals ==\n",
            "The general problem of simulating (...\n",
            "> Adding chunk: == Goals ==\n",
            "The general problem of simulating (...\n",
            "> Adding chunk: == Goals ==\n",
            "The general problem of simulating (...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Planning and decision-making ===\n",
            "An \"agent\"...\n",
            "> Adding chunk: === Planning and decision-making ===\n",
            "An \"agent\"...\n",
            "> Adding chunk: === Planning and decision-making ===\n",
            "An \"agent\"...\n",
            "> Adding chunk: === Planning and decision-making ===\n",
            "An \"agent\"...\n",
            "> Adding chunk: === Planning and decision-making ===\n",
            "An \"agent\"...\n",
            "> Adding chunk: === Planning and decision-making ===\n",
            "An \"agent\"...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Learning ===\n",
            "Machine learning is the study ...\n",
            "> Adding chunk: === Learning ===\n",
            "Machine learning is the study ...\n",
            "> Adding chunk: === Learning ===\n",
            "Machine learning is the study ...\n",
            "> Adding chunk: === Learning ===\n",
            "Machine learning is the study ...\n",
            "> Adding chunk: === Learning ===\n",
            "Machine learning is the study ...\n",
            "> Adding chunk: === Learning ===\n",
            "Machine learning is the study ...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Perception ===\n",
            "Machine perception is the ab...\n",
            "> Adding chunk: === Perception ===\n",
            "Machine perception is the ab...\n",
            "> Adding chunk: === Perception ===\n",
            "Machine perception is the ab...\n",
            "> Adding chunk: === Perception ===\n",
            "Machine perception is the ab...\n",
            "> Adding chunk: === Perception ===\n",
            "Machine perception is the ab...\n",
            "> Adding chunk: === Perception ===\n",
            "Machine perception is the ab...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: ==== Local search ====\n",
            " Local search uses mathe...\n",
            "> Adding chunk: ==== Local search ====\n",
            " Local search uses mathe...\n",
            "> Adding chunk: ==== Local search ====\n",
            " Local search uses mathe...\n",
            "> Adding chunk: ==== Local search ====\n",
            " Local search uses mathe...\n",
            "> Adding chunk: ==== Local search ====\n",
            " Local search uses mathe...\n",
            "> Adding chunk: ==== Local search ====\n",
            " Local search uses mathe...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Logic ===\n",
            "Formal logic is used for reasonin...\n",
            "> Adding chunk: === Logic ===\n",
            "Formal logic is used for reasonin...\n",
            "> Adding chunk: === Logic ===\n",
            "Formal logic is used for reasonin...\n",
            "> Adding chunk: === Logic ===\n",
            "Formal logic is used for reasonin...\n",
            "> Adding chunk: === Logic ===\n",
            "Formal logic is used for reasonin...\n",
            "> Adding chunk: === Logic ===\n",
            "Formal logic is used for reasonin...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Probabilistic methods for uncertain reasoni...\n",
            "> Adding chunk: === Probabilistic methods for uncertain reasoni...\n",
            "> Adding chunk: === Probabilistic methods for uncertain reasoni...\n",
            "> Adding chunk: === Probabilistic methods for uncertain reasoni...\n",
            "> Adding chunk: === Probabilistic methods for uncertain reasoni...\n",
            "> Adding chunk: === Probabilistic methods for uncertain reasoni...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Artificial neural networks ===\n",
            "\n",
            "An artifici...\n",
            "> Adding chunk: === Artificial neural networks ===\n",
            "\n",
            "An artifici...\n",
            "> Adding chunk: === Artificial neural networks ===\n",
            "\n",
            "An artifici...\n",
            "> Adding chunk: === Artificial neural networks ===\n",
            "\n",
            "An artifici...\n",
            "> Adding chunk: === Artificial neural networks ===\n",
            "\n",
            "An artifici...\n",
            "> Adding chunk: === Artificial neural networks ===\n",
            "\n",
            "An artifici...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Deep learning ===\n",
            "\n",
            "Deep learning uses sever...\n",
            "> Adding chunk: === Deep learning ===\n",
            "\n",
            "Deep learning uses sever...\n",
            "> Adding chunk: === Deep learning ===\n",
            "\n",
            "Deep learning uses sever...\n",
            "> Adding chunk: === Deep learning ===\n",
            "\n",
            "Deep learning uses sever...\n",
            "> Adding chunk: === Deep learning ===\n",
            "\n",
            "Deep learning uses sever...\n",
            "> Adding chunk: === Deep learning ===\n",
            "\n",
            "Deep learning uses sever...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Hardware and software ===\n",
            "\n",
            "In the late 2010...\n",
            "> Adding chunk: === Hardware and software ===\n",
            "\n",
            "In the late 2010...\n",
            "> Adding chunk: === Hardware and software ===\n",
            "\n",
            "In the late 2010...\n",
            "> Adding chunk: === Hardware and software ===\n",
            "\n",
            "In the late 2010...\n",
            "> Adding chunk: === Hardware and software ===\n",
            "\n",
            "In the late 2010...\n",
            "> Adding chunk: === Hardware and software ===\n",
            "\n",
            "In the late 2010...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Health and medicine ===\n",
            "\n",
            "The application of...\n",
            "> Adding chunk: === Health and medicine ===\n",
            "\n",
            "The application of...\n",
            "> Adding chunk: === Health and medicine ===\n",
            "\n",
            "The application of...\n",
            "> Adding chunk: === Health and medicine ===\n",
            "\n",
            "The application of...\n",
            "> Adding chunk: === Health and medicine ===\n",
            "\n",
            "The application of...\n",
            "> Adding chunk: === Health and medicine ===\n",
            "\n",
            "The application of...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Games ===\n",
            "\n",
            "Game playing programs have been ...\n",
            "> Adding chunk: === Games ===\n",
            "\n",
            "Game playing programs have been ...\n",
            "> Adding chunk: === Games ===\n",
            "\n",
            "Game playing programs have been ...\n",
            "> Adding chunk: === Games ===\n",
            "\n",
            "Game playing programs have been ...\n",
            "> Adding chunk: === Games ===\n",
            "\n",
            "Game playing programs have been ...\n",
            "> Adding chunk: === Games ===\n",
            "\n",
            "Game playing programs have been ...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Mathematics ===\n",
            "Large language models, such...\n",
            "> Adding chunk: === Mathematics ===\n",
            "Large language models, such...\n",
            "> Adding chunk: === Mathematics ===\n",
            "Large language models, such...\n",
            "> Adding chunk: === Mathematics ===\n",
            "Large language models, such...\n",
            "> Adding chunk: === Mathematics ===\n",
            "Large language models, such...\n",
            "> Adding chunk: === Mathematics ===\n",
            "Large language models, such...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Military ===\n",
            "\n",
            "Various countries are deployi...\n",
            "> Adding chunk: === Military ===\n",
            "\n",
            "Various countries are deployi...\n",
            "> Adding chunk: === Military ===\n",
            "\n",
            "Various countries are deployi...\n",
            "> Adding chunk: === Military ===\n",
            "\n",
            "Various countries are deployi...\n",
            "> Adding chunk: === Military ===\n",
            "\n",
            "Various countries are deployi...\n",
            "> Adding chunk: === Military ===\n",
            "\n",
            "Various countries are deployi...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Other industry-specific tasks ===\n",
            "There are...\n",
            "> Adding chunk: === Other industry-specific tasks ===\n",
            "There are...\n",
            "> Adding chunk: === Other industry-specific tasks ===\n",
            "There are...\n",
            "> Adding chunk: === Other industry-specific tasks ===\n",
            "There are...\n",
            "> Adding chunk: === Other industry-specific tasks ===\n",
            "There are...\n",
            "> Adding chunk: === Other industry-specific tasks ===\n",
            "There are...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Risks and harm ===\n",
            "\n",
            "\n",
            "==== Privacy and copyr...\n",
            "> Adding chunk: === Risks and harm ===\n",
            "\n",
            "\n",
            "==== Privacy and copyr...\n",
            "> Adding chunk: === Risks and harm ===\n",
            "\n",
            "\n",
            "==== Privacy and copyr...\n",
            "> Adding chunk: === Risks and harm ===\n",
            "\n",
            "\n",
            "==== Privacy and copyr...\n",
            "> Adding chunk: === Risks and harm ===\n",
            "\n",
            "\n",
            "==== Privacy and copyr...\n",
            "> Adding chunk: === Risks and harm ===\n",
            "\n",
            "\n",
            "==== Privacy and copyr...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: ==== Dominance by tech giants ====\n",
            "The commerci...\n",
            "> Adding chunk: ==== Dominance by tech giants ====\n",
            "The commerci...\n",
            "> Adding chunk: ==== Dominance by tech giants ====\n",
            "The commerci...\n",
            "> Adding chunk: ==== Dominance by tech giants ====\n",
            "The commerci...\n",
            "> Adding chunk: ==== Dominance by tech giants ====\n",
            "The commerci...\n",
            "> Adding chunk: ==== Dominance by tech giants ====\n",
            "The commerci...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: The Big Tech companies counter that AI can be u...\n",
            "> Adding chunk: The Big Tech companies counter that AI can be u...\n",
            "> Adding chunk: The Big Tech companies counter that AI can be u...\n",
            "> Adding chunk: The Big Tech companies counter that AI can be u...\n",
            "> Adding chunk: The Big Tech companies counter that AI can be u...\n",
            "> Adding chunk: The Big Tech companies counter that AI can be u...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: Although most nuclear plants in Japan have been...\n",
            "> Adding chunk: Although most nuclear plants in Japan have been...\n",
            "> Adding chunk: Although most nuclear plants in Japan have been...\n",
            "> Adding chunk: Although most nuclear plants in Japan have been...\n",
            "> Adding chunk: Although most nuclear plants in Japan have been...\n",
            "> Adding chunk: Although most nuclear plants in Japan have been...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: If a biased algorithm is used to make decisions...\n",
            "> Adding chunk: If a biased algorithm is used to make decisions...\n",
            "> Adding chunk: If a biased algorithm is used to make decisions...\n",
            "> Adding chunk: If a biased algorithm is used to make decisions...\n",
            "> Adding chunk: If a biased algorithm is used to make decisions...\n",
            "> Adding chunk: If a biased algorithm is used to make decisions...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: If an application then uses these predictions a...\n",
            "> Adding chunk: If an application then uses these predictions a...\n",
            "> Adding chunk: If an application then uses these predictions a...\n",
            "> Adding chunk: If an application then uses these predictions a...\n",
            "> Adding chunk: If an application then uses these predictions a...\n",
            "> Adding chunk: If an application then uses these predictions a...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: ==== Lack of transparency ====\n",
            "\n",
            "Many AI systems...\n",
            "> Adding chunk: ==== Lack of transparency ====\n",
            "\n",
            "Many AI systems...\n",
            "> Adding chunk: ==== Lack of transparency ====\n",
            "\n",
            "Many AI systems...\n",
            "> Adding chunk: ==== Lack of transparency ====\n",
            "\n",
            "Many AI systems...\n",
            "> Adding chunk: ==== Lack of transparency ====\n",
            "\n",
            "Many AI systems...\n",
            "> Adding chunk: ==== Lack of transparency ====\n",
            "\n",
            "Many AI systems...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: ==== Bad actors and weaponized AI ====\n",
            "\n",
            "Artific...\n",
            "> Adding chunk: ==== Bad actors and weaponized AI ====\n",
            "\n",
            "Artific...\n",
            "> Adding chunk: ==== Bad actors and weaponized AI ====\n",
            "\n",
            "Artific...\n",
            "> Adding chunk: ==== Bad actors and weaponized AI ====\n",
            "\n",
            "Artific...\n",
            "> Adding chunk: ==== Bad actors and weaponized AI ====\n",
            "\n",
            "Artific...\n",
            "> Adding chunk: ==== Bad actors and weaponized AI ====\n",
            "\n",
            "Artific...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: ==== Technological unemployment ====\n",
            "\n",
            "Economist...\n",
            "> Adding chunk: ==== Technological unemployment ====\n",
            "\n",
            "Economist...\n",
            "> Adding chunk: ==== Technological unemployment ====\n",
            "\n",
            "Economist...\n",
            "> Adding chunk: ==== Technological unemployment ====\n",
            "\n",
            "Economist...\n",
            "> Adding chunk: ==== Technological unemployment ====\n",
            "\n",
            "Economist...\n",
            "> Adding chunk: ==== Technological unemployment ====\n",
            "\n",
            "Economist...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: First, AI does not require human-like sentience...\n",
            "> Adding chunk: First, AI does not require human-like sentience...\n",
            "> Adding chunk: First, AI does not require human-like sentience...\n",
            "> Adding chunk: First, AI does not require human-like sentience...\n",
            "> Adding chunk: First, AI does not require human-like sentience...\n",
            "> Adding chunk: First, AI does not require human-like sentience...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: While the tools that are now being used to impr...\n",
            "> Adding chunk: While the tools that are now being used to impr...\n",
            "> Adding chunk: While the tools that are now being used to impr...\n",
            "> Adding chunk: While the tools that are now being used to impr...\n",
            "> Adding chunk: While the tools that are now being used to impr...\n",
            "> Adding chunk: While the tools that are now being used to impr...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Frameworks ===\n",
            "Artificial Intelligence proj...\n",
            "> Adding chunk: === Frameworks ===\n",
            "Artificial Intelligence proj...\n",
            "> Adding chunk: === Frameworks ===\n",
            "Artificial Intelligence proj...\n",
            "> Adding chunk: === Frameworks ===\n",
            "Artificial Intelligence proj...\n",
            "> Adding chunk: === Frameworks ===\n",
            "Artificial Intelligence proj...\n",
            "> Adding chunk: === Frameworks ===\n",
            "Artificial Intelligence proj...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: Henry Kissinger, Eric Schmidt, and Daniel Hutte...\n",
            "> Adding chunk: Henry Kissinger, Eric Schmidt, and Daniel Hutte...\n",
            "> Adding chunk: Henry Kissinger, Eric Schmidt, and Daniel Hutte...\n",
            "> Adding chunk: Henry Kissinger, Eric Schmidt, and Daniel Hutte...\n",
            "> Adding chunk: Henry Kissinger, Eric Schmidt, and Daniel Hutte...\n",
            "> Adding chunk: Henry Kissinger, Eric Schmidt, and Daniel Hutte...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: They developed several areas of research that w...\n",
            "> Adding chunk: They developed several areas of research that w...\n",
            "> Adding chunk: They developed several areas of research that w...\n",
            "> Adding chunk: They developed several areas of research that w...\n",
            "> Adding chunk: They developed several areas of research that w...\n",
            "> Adding chunk: They developed several areas of research that w...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: Up to this point, most of AI's funding had gone...\n",
            "> Adding chunk: Up to this point, most of AI's funding had gone...\n",
            "> Adding chunk: Up to this point, most of AI's funding had gone...\n",
            "> Adding chunk: Up to this point, most of AI's funding had gone...\n",
            "> Adding chunk: Up to this point, most of AI's funding had gone...\n",
            "> Adding chunk: Up to this point, most of AI's funding had gone...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: In 2016, issues of fairness and the misuse of t...\n",
            "> Adding chunk: In 2016, issues of fairness and the misuse of t...\n",
            "> Adding chunk: In 2016, issues of fairness and the misuse of t...\n",
            "> Adding chunk: In 2016, issues of fairness and the misuse of t...\n",
            "> Adding chunk: In 2016, issues of fairness and the misuse of t...\n",
            "> Adding chunk: In 2016, issues of fairness and the misuse of t...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Defining artificial intelligence ===\n",
            "\n",
            "Alan ...\n",
            "> Adding chunk: === Defining artificial intelligence ===\n",
            "\n",
            "Alan ...\n",
            "> Adding chunk: === Defining artificial intelligence ===\n",
            "\n",
            "Alan ...\n",
            "> Adding chunk: === Defining artificial intelligence ===\n",
            "\n",
            "Alan ...\n",
            "> Adding chunk: === Defining artificial intelligence ===\n",
            "\n",
            "Alan ...\n",
            "> Adding chunk: === Defining artificial intelligence ===\n",
            "\n",
            "Alan ...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Evaluating approaches to AI ===\n",
            "No establis...\n",
            "> Adding chunk: === Evaluating approaches to AI ===\n",
            "No establis...\n",
            "> Adding chunk: === Evaluating approaches to AI ===\n",
            "No establis...\n",
            "> Adding chunk: === Evaluating approaches to AI ===\n",
            "No establis...\n",
            "> Adding chunk: === Evaluating approaches to AI ===\n",
            "No establis...\n",
            "> Adding chunk: === Evaluating approaches to AI ===\n",
            "No establis...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: ==== Neat vs. scruffy ====\n",
            "\n",
            "\"Neats\" hope that i...\n",
            "> Adding chunk: ==== Neat vs. scruffy ====\n",
            "\n",
            "\"Neats\" hope that i...\n",
            "> Adding chunk: ==== Neat vs. scruffy ====\n",
            "\n",
            "\"Neats\" hope that i...\n",
            "> Adding chunk: ==== Neat vs. scruffy ====\n",
            "\n",
            "\"Neats\" hope that i...\n",
            "> Adding chunk: ==== Neat vs. scruffy ====\n",
            "\n",
            "\"Neats\" hope that i...\n",
            "> Adding chunk: ==== Neat vs. scruffy ====\n",
            "\n",
            "\"Neats\" hope that i...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: ==== Consciousness ====\n",
            "\n",
            "David Chalmers identif...\n",
            "> Adding chunk: ==== Consciousness ====\n",
            "\n",
            "David Chalmers identif...\n",
            "> Adding chunk: ==== Consciousness ====\n",
            "\n",
            "David Chalmers identif...\n",
            "> Adding chunk: ==== Consciousness ====\n",
            "\n",
            "David Chalmers identif...\n",
            "> Adding chunk: ==== Consciousness ====\n",
            "\n",
            "David Chalmers identif...\n",
            "> Adding chunk: ==== Consciousness ====\n",
            "\n",
            "David Chalmers identif...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: ==== AI welfare and rights ====\n",
            "It is difficult...\n",
            "> Adding chunk: ==== AI welfare and rights ====\n",
            "It is difficult...\n",
            "> Adding chunk: ==== AI welfare and rights ====\n",
            "It is difficult...\n",
            "> Adding chunk: ==== AI welfare and rights ====\n",
            "It is difficult...\n",
            "> Adding chunk: ==== AI welfare and rights ====\n",
            "It is difficult...\n",
            "> Adding chunk: ==== AI welfare and rights ====\n",
            "It is difficult...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: === Transhumanism ===\n",
            "\n",
            "Robot designer Hans Mora...\n",
            "> Adding chunk: === Transhumanism ===\n",
            "\n",
            "Robot designer Hans Mora...\n",
            "> Adding chunk: === Transhumanism ===\n",
            "\n",
            "Robot designer Hans Mora...\n",
            "> Adding chunk: === Transhumanism ===\n",
            "\n",
            "Robot designer Hans Mora...\n",
            "> Adding chunk: === Transhumanism ===\n",
            "\n",
            "Robot designer Hans Mora...\n",
            "> Adding chunk: === Transhumanism ===\n",
            "\n",
            "Robot designer Hans Mora...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: == In fiction ==\n",
            "\n",
            "Thought-capable artificial be...\n",
            "> Adding chunk: == In fiction ==\n",
            "\n",
            "Thought-capable artificial be...\n",
            "> Adding chunk: == In fiction ==\n",
            "\n",
            "Thought-capable artificial be...\n",
            "> Adding chunk: == In fiction ==\n",
            "\n",
            "Thought-capable artificial be...\n",
            "> Adding chunk: == In fiction ==\n",
            "\n",
            "Thought-capable artificial be...\n",
            "> Adding chunk: == In fiction ==\n",
            "\n",
            "Thought-capable artificial be...\n",
            "DEBUG:llama_index.node_parser.node_utils:> Adding chunk: == See also ==\n",
            "Artificial intelligence and elec...\n",
            "> Adding chunk: == See also ==\n",
            "Artificial intelligence and elec...\n",
            "> Adding chunk: == See also ==\n",
            "Artificial intelligence and elec...\n",
            "> Adding chunk: == See also ==\n",
            "Artificial intelligence and elec...\n",
            "> Adding chunk: == See also ==\n",
            "Artificial intelligence and elec...\n",
            "> Adding chunk: == See also ==\n",
            "Artificial intelligence and elec...\n",
            "58\n"
          ]
        }
      ],
      "source": [
        "from llama_index.node_parser import SimpleNodeParser\n",
        "\n",
        "# Assuming documents have already been loaded\n",
        "\n",
        "# Initialize the parser\n",
        "parser = SimpleNodeParser.from_defaults(chunk_size=512, chunk_overlap=20)\n",
        "\n",
        "# Parse documents into nodes\n",
        "nodes = parser.get_nodes_from_documents(documents)\n",
        "print( len( nodes ) )"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "03lff4VUTaN9"
      },
      "source": [
        "# Save on DeepLake"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eo8CTHSFTcaR",
        "outputId": "adbf0c99-61ec-4879-eede-15d7cd7e8d60"
      },
      "outputs": [],
      "source": [
        "from llama_index.vector_stores import DeepLakeVectorStore\n",
        "\n",
        "my_activeloop_org_id = \"hellum\"\n",
        "my_activeloop_dataset_name = \"LlamaIndex_intro\"\n",
        "dataset_path = f\"hub://{my_activeloop_org_id}/{my_activeloop_dataset_name}\"\n",
        "\n",
        "# Create an index over the documnts\n",
        "vector_store = DeepLakeVectorStore(dataset_path=dataset_path, overwrite=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 53,
      "metadata": {
        "id": "eWFtVpM_TcTQ"
      },
      "outputs": [],
      "source": [
        "from llama_index.storage.storage_context import StorageContext\n",
        "\n",
        "storage_context = StorageContext.from_defaults(vector_store=vector_store)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g3GCf8LrULIW",
        "outputId": "9e40d8fb-5863-4de0-c49c-f593463a2c0c"
      },
      "outputs": [],
      "source": [
        "from llama_index import VectorStoreIndex\n",
        "\n",
        "index = VectorStoreIndex.from_documents(\n",
        "    documents, storage_context=storage_context\n",
        ")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kCgdd197CTDt"
      },
      "source": [
        "# Create index from Documents"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "G7BdNn-Q5AlG",
        "outputId": "2f78963e-830e-45bd-c6f8-50a99be55cbf"
      },
      "outputs": [],
      "source": [
        "from llama_index import GPTVectorStoreIndex\n",
        "\n",
        "index = GPTVectorStoreIndex.from_documents(documents)\n",
        "query_engine = index.as_query_engine()\n",
        "response = query_engine.query(\"What does NLP stands for?\")\n",
        "response.response"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mtGKUVg3wI0d"
      },
      "source": [
        "# Environment"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sKHDHMsIwIGp",
        "outputId": "4865ddd8-6d81-4f17-c1b0-a877065d2ec7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Package                          Version\n",
            "-------------------------------- ---------------------\n",
            "absl-py                          1.4.0\n",
            "aiohttp                          3.9.1\n",
            "aiosignal                        1.3.1\n",
            "alabaster                        0.7.13\n",
            "albumentations                   1.3.1\n",
            "altair                           4.2.2\n",
            "anyio                            3.7.1\n",
            "appdirs                          1.4.4\n",
            "argon2-cffi                      23.1.0\n",
            "argon2-cffi-bindings             21.2.0\n",
            "array-record                     0.5.0\n",
            "arviz                            0.15.1\n",
            "astropy                          5.3.4\n",
            "astunparse                       1.6.3\n",
            "async-timeout                    4.0.3\n",
            "atpublic                         4.0\n",
            "attrs                            23.1.0\n",
            "audioread                        3.0.1\n",
            "autograd                         1.6.2\n",
            "Babel                            2.13.1\n",
            "backcall                         0.2.0\n",
            "backoff                          2.2.1\n",
            "beautifulsoup4                   4.12.2\n",
            "bidict                           0.22.1\n",
            "bigframes                        0.15.0\n",
            "bleach                           6.1.0\n",
            "blinker                          1.4\n",
            "blis                             0.7.11\n",
            "blosc2                           2.0.0\n",
            "bokeh                            3.3.2\n",
            "bqplot                           0.12.42\n",
            "branca                           0.7.0\n",
            "build                            1.0.3\n",
            "CacheControl                     0.13.1\n",
            "cachetools                       5.3.2\n",
            "catalogue                        2.0.10\n",
            "certifi                          2023.11.17\n",
            "cffi                             1.16.0\n",
            "chardet                          5.2.0\n",
            "charset-normalizer               3.3.2\n",
            "chex                             0.1.7\n",
            "click                            8.1.7\n",
            "click-plugins                    1.1.1\n",
            "cligj                            0.7.2\n",
            "cloudpickle                      2.2.1\n",
            "cmake                            3.27.9\n",
            "cmdstanpy                        1.2.0\n",
            "cohere                           4.37\n",
            "colorcet                         3.0.1\n",
            "colorlover                       0.3.0\n",
            "colour                           0.1.5\n",
            "community                        1.0.0b1\n",
            "confection                       0.1.4\n",
            "cons                             0.4.6\n",
            "contextlib2                      21.6.0\n",
            "contourpy                        1.2.0\n",
            "cryptography                     41.0.7\n",
            "cufflinks                        0.17.3\n",
            "cupy-cuda11x                     11.0.0\n",
            "cvxopt                           1.3.2\n",
            "cvxpy                            1.3.2\n",
            "cycler                           0.12.1\n",
            "cymem                            2.0.8\n",
            "Cython                           3.0.6\n",
            "dask                             2023.8.1\n",
            "dataclasses-json                 0.6.3\n",
            "datascience                      0.17.6\n",
            "db-dtypes                        1.1.1\n",
            "dbus-python                      1.2.18\n",
            "debugpy                          1.6.6\n",
            "decorator                        4.4.2\n",
            "defusedxml                       0.7.1\n",
            "Deprecated                       1.2.14\n",
            "diskcache                        5.6.3\n",
            "distributed                      2023.8.1\n",
            "distro                           1.7.0\n",
            "dlib                             19.24.2\n",
            "dm-tree                          0.1.8\n",
            "docutils                         0.18.1\n",
            "dopamine-rl                      4.0.6\n",
            "duckdb                           0.9.2\n",
            "earthengine-api                  0.1.381\n",
            "easydict                         1.11\n",
            "ecos                             2.0.12\n",
            "editdistance                     0.6.2\n",
            "eerepr                           0.0.4\n",
            "en-core-web-sm                   3.6.0\n",
            "entrypoints                      0.4\n",
            "et-xmlfile                       1.1.0\n",
            "etils                            1.5.2\n",
            "etuples                          0.3.9\n",
            "exceptiongroup                   1.2.0\n",
            "fastai                           2.7.13\n",
            "fastavro                         1.9.1\n",
            "fastcore                         1.5.29\n",
            "fastdownload                     0.0.7\n",
            "fastjsonschema                   2.19.0\n",
            "fastprogress                     1.0.3\n",
            "fastrlock                        0.8.2\n",
            "filelock                         3.13.1\n",
            "fiona                            1.9.5\n",
            "firebase-admin                   5.3.0\n",
            "Flask                            2.2.5\n",
            "flatbuffers                      23.5.26\n",
            "flax                             0.7.5\n",
            "folium                           0.14.0\n",
            "fonttools                        4.46.0\n",
            "frozendict                       2.3.10\n",
            "frozenlist                       1.4.0\n",
            "fsspec                           2023.6.0\n",
            "future                           0.18.3\n",
            "gast                             0.5.4\n",
            "gcsfs                            2023.6.0\n",
            "GDAL                             3.4.3\n",
            "gdown                            4.6.6\n",
            "geemap                           0.29.6\n",
            "gensim                           4.3.2\n",
            "geocoder                         1.38.1\n",
            "geographiclib                    2.0\n",
            "geopandas                        0.13.2\n",
            "geopy                            2.3.0\n",
            "gin-config                       0.5.0\n",
            "glob2                            0.7\n",
            "google                           2.0.3\n",
            "google-ai-generativelanguage     0.3.3\n",
            "google-api-core                  2.11.1\n",
            "google-api-python-client         2.84.0\n",
            "google-auth                      2.17.3\n",
            "google-auth-httplib2             0.1.1\n",
            "google-auth-oauthlib             1.0.0\n",
            "google-cloud-aiplatform          1.36.4\n",
            "google-cloud-bigquery            3.12.0\n",
            "google-cloud-bigquery-connection 1.12.1\n",
            "google-cloud-bigquery-storage    2.23.0\n",
            "google-cloud-core                2.3.3\n",
            "google-cloud-datastore           2.15.2\n",
            "google-cloud-firestore           2.11.1\n",
            "google-cloud-functions           1.13.3\n",
            "google-cloud-iam                 2.12.2\n",
            "google-cloud-language            2.9.1\n",
            "google-cloud-resource-manager    1.10.4\n",
            "google-cloud-storage             2.8.0\n",
            "google-cloud-translate           3.11.3\n",
            "google-colab                     1.0.0\n",
            "google-crc32c                    1.5.0\n",
            "google-generativeai              0.2.2\n",
            "google-pasta                     0.2.0\n",
            "google-resumable-media           2.6.0\n",
            "googleapis-common-protos         1.61.0\n",
            "googledrivedownloader            0.4\n",
            "graphviz                         0.20.1\n",
            "greenlet                         3.0.1\n",
            "grpc-google-iam-v1               0.12.7\n",
            "grpcio                           1.59.3\n",
            "grpcio-status                    1.48.2\n",
            "gspread                          3.4.2\n",
            "gspread-dataframe                3.3.1\n",
            "gym                              0.25.2\n",
            "gym-notices                      0.0.8\n",
            "h11                              0.14.0\n",
            "h5netcdf                         1.3.0\n",
            "h5py                             3.9.0\n",
            "holidays                         0.38\n",
            "holoviews                        1.17.1\n",
            "html5lib                         1.1\n",
            "httpcore                         1.0.2\n",
            "httpimport                       1.3.1\n",
            "httplib2                         0.22.0\n",
            "httpx                            0.25.2\n",
            "huggingface-hub                  0.19.4\n",
            "humanize                         4.7.0\n",
            "hyperopt                         0.2.7\n",
            "ibis-framework                   6.2.0\n",
            "idna                             3.6\n",
            "imageio                          2.31.6\n",
            "imageio-ffmpeg                   0.4.9\n",
            "imagesize                        1.4.1\n",
            "imbalanced-learn                 0.10.1\n",
            "imgaug                           0.4.0\n",
            "importlib-metadata               6.11.0\n",
            "importlib-resources              6.1.1\n",
            "imutils                          0.5.4\n",
            "inflect                          7.0.0\n",
            "iniconfig                        2.0.0\n",
            "install                          1.3.5\n",
            "intel-openmp                     2023.2.0\n",
            "ipyevents                        2.0.2\n",
            "ipyfilechooser                   0.6.0\n",
            "ipykernel                        5.5.6\n",
            "ipyleaflet                       0.18.0\n",
            "ipython                          7.34.0\n",
            "ipython-genutils                 0.2.0\n",
            "ipython-sql                      0.5.0\n",
            "ipytree                          0.2.2\n",
            "ipywidgets                       7.7.1\n",
            "itsdangerous                     2.1.2\n",
            "jax                              0.4.20\n",
            "jaxlib                           0.4.20+cuda11.cudnn86\n",
            "jeepney                          0.7.1\n",
            "jieba                            0.42.1\n",
            "Jinja2                           3.1.2\n",
            "joblib                           1.3.2\n",
            "jsonpickle                       3.0.2\n",
            "jsonschema                       4.19.2\n",
            "jsonschema-specifications        2023.11.2\n",
            "jupyter-client                   6.1.12\n",
            "jupyter-console                  6.1.0\n",
            "jupyter_core                     5.5.0\n",
            "jupyter-server                   1.24.0\n",
            "jupyterlab_pygments              0.3.0\n",
            "jupyterlab-widgets               3.0.9\n",
            "kaggle                           1.5.16\n",
            "keras                            2.14.0\n",
            "keyring                          23.5.0\n",
            "kiwisolver                       1.4.5\n",
            "langcodes                        3.3.0\n",
            "launchpadlib                     1.10.16\n",
            "lazr.restfulclient               0.14.4\n",
            "lazr.uri                         1.0.6\n",
            "lazy_loader                      0.3\n",
            "libclang                         16.0.6\n",
            "librosa                          0.10.1\n",
            "lida                             0.0.10\n",
            "lightgbm                         4.1.0\n",
            "linkify-it-py                    2.0.2\n",
            "llama-index                      0.9.14.post3\n",
            "llmx                             0.0.15a0\n",
            "llvmlite                         0.41.1\n",
            "locket                           1.0.0\n",
            "logical-unification              0.4.6\n",
            "lxml                             4.9.3\n",
            "malloy                           2023.1067\n",
            "Markdown                         3.5.1\n",
            "markdown-it-py                   3.0.0\n",
            "MarkupSafe                       2.1.3\n",
            "marshmallow                      3.20.1\n",
            "matplotlib                       3.7.1\n",
            "matplotlib-inline                0.1.6\n",
            "matplotlib-venn                  0.11.9\n",
            "mdit-py-plugins                  0.4.0\n",
            "mdurl                            0.1.2\n",
            "miniKanren                       1.0.3\n",
            "missingno                        0.5.2\n",
            "mistune                          0.8.4\n",
            "mizani                           0.9.3\n",
            "mkl                              2023.2.0\n",
            "ml-dtypes                        0.2.0\n",
            "mlxtend                          0.22.0\n",
            "more-itertools                   10.1.0\n",
            "moviepy                          1.0.3\n",
            "mpmath                           1.3.0\n",
            "msgpack                          1.0.7\n",
            "multidict                        6.0.4\n",
            "multipledispatch                 1.0.0\n",
            "multitasking                     0.0.11\n",
            "murmurhash                       1.0.10\n",
            "music21                          9.1.0\n",
            "mypy-extensions                  1.0.0\n",
            "natsort                          8.4.0\n",
            "nbclassic                        1.0.0\n",
            "nbclient                         0.9.0\n",
            "nbconvert                        6.5.4\n",
            "nbformat                         5.9.2\n",
            "nest-asyncio                     1.5.8\n",
            "networkx                         3.2.1\n",
            "nibabel                          4.0.2\n",
            "nltk                             3.8.1\n",
            "notebook                         6.5.5\n",
            "notebook_shim                    0.2.3\n",
            "numba                            0.58.1\n",
            "numexpr                          2.8.7\n",
            "numpy                            1.23.5\n",
            "oauth2client                     4.1.3\n",
            "oauthlib                         3.2.2\n",
            "openai                           1.3.8\n",
            "opencv-contrib-python            4.8.0.76\n",
            "opencv-python                    4.8.0.76\n",
            "opencv-python-headless           4.8.1.78\n",
            "openpyxl                         3.1.2\n",
            "opt-einsum                       3.3.0\n",
            "optax                            0.1.7\n",
            "orbax-checkpoint                 0.4.4\n",
            "osqp                             0.6.2.post8\n",
            "packaging                        23.2\n",
            "pandas                           1.5.3\n",
            "pandas-datareader                0.10.0\n",
            "pandas-gbq                       0.19.2\n",
            "pandas-stubs                     1.5.3.230304\n",
            "pandocfilters                    1.5.0\n",
            "panel                            1.3.4\n",
            "param                            2.0.1\n",
            "parso                            0.8.3\n",
            "parsy                            2.1\n",
            "partd                            1.4.1\n",
            "pathlib                          1.0.1\n",
            "pathy                            0.10.3\n",
            "patsy                            0.5.4\n",
            "peewee                           3.17.0\n",
            "pexpect                          4.9.0\n",
            "pickleshare                      0.7.5\n",
            "Pillow                           9.4.0\n",
            "pip                              23.1.2\n",
            "pip-tools                        6.13.0\n",
            "platformdirs                     4.1.0\n",
            "plotly                           5.15.0\n",
            "plotnine                         0.12.4\n",
            "pluggy                           1.3.0\n",
            "polars                           0.17.3\n",
            "pooch                            1.8.0\n",
            "portpicker                       1.5.2\n",
            "prefetch-generator               1.0.3\n",
            "preshed                          3.0.9\n",
            "prettytable                      3.9.0\n",
            "proglog                          0.1.10\n",
            "progressbar2                     4.2.0\n",
            "prometheus-client                0.19.0\n",
            "promise                          2.3\n",
            "prompt-toolkit                   3.0.41\n",
            "prophet                          1.1.5\n",
            "proto-plus                       1.22.3\n",
            "protobuf                         3.20.3\n",
            "psutil                           5.9.5\n",
            "psycopg2                         2.9.9\n",
            "ptyprocess                       0.7.0\n",
            "py-cpuinfo                       9.0.0\n",
            "py4j                             0.10.9.7\n",
            "pyarrow                          10.0.1\n",
            "pyasn1                           0.5.1\n",
            "pyasn1-modules                   0.3.0\n",
            "pycocotools                      2.0.7\n",
            "pycparser                        2.21\n",
            "pyct                             0.5.0\n",
            "pydantic                         1.10.13\n",
            "pydata-google-auth               1.8.2\n",
            "pydot                            1.4.2\n",
            "pydot-ng                         2.0.0\n",
            "pydotplus                        2.0.2\n",
            "PyDrive                          1.3.1\n",
            "PyDrive2                         1.6.3\n",
            "pyerfa                           2.0.1.1\n",
            "pygame                           2.5.2\n",
            "Pygments                         2.16.1\n",
            "PyGObject                        3.42.1\n",
            "PyJWT                            2.3.0\n",
            "pymc                             5.7.2\n",
            "pymystem3                        0.2.0\n",
            "PyOpenGL                         3.1.7\n",
            "pyOpenSSL                        23.3.0\n",
            "pyparsing                        3.1.1\n",
            "pyperclip                        1.8.2\n",
            "pyproj                           3.6.1\n",
            "pyproject_hooks                  1.0.0\n",
            "pyshp                            2.3.1\n",
            "PySocks                          1.7.1\n",
            "pytensor                         2.14.2\n",
            "pytest                           7.4.3\n",
            "python-apt                       0.0.0\n",
            "python-box                       7.1.1\n",
            "python-dateutil                  2.8.2\n",
            "python-louvain                   0.16\n",
            "python-slugify                   8.0.1\n",
            "python-utils                     3.8.1\n",
            "pytz                             2023.3.post1\n",
            "pyviz_comms                      3.0.0\n",
            "PyWavelets                       1.5.0\n",
            "PyYAML                           6.0.1\n",
            "pyzmq                            23.2.1\n",
            "qdldl                            0.1.7.post0\n",
            "qudida                           0.0.4\n",
            "ratelim                          0.1.6\n",
            "referencing                      0.31.1\n",
            "regex                            2023.6.3\n",
            "requests                         2.31.0\n",
            "requests-oauthlib                1.3.1\n",
            "requirements-parser              0.5.0\n",
            "rich                             13.7.0\n",
            "rpds-py                          0.13.2\n",
            "rpy2                             3.4.2\n",
            "rsa                              4.9\n",
            "safetensors                      0.4.1\n",
            "scikit-image                     0.19.3\n",
            "scikit-learn                     1.2.2\n",
            "scipy                            1.11.4\n",
            "scooby                           0.9.2\n",
            "scs                              3.2.4.post1\n",
            "seaborn                          0.12.2\n",
            "SecretStorage                    3.3.1\n",
            "Send2Trash                       1.8.2\n",
            "setuptools                       67.7.2\n",
            "shapely                          2.0.2\n",
            "six                              1.16.0\n",
            "sklearn-pandas                   2.2.0\n",
            "smart-open                       6.4.0\n",
            "sniffio                          1.3.0\n",
            "snowballstemmer                  2.2.0\n",
            "sortedcontainers                 2.4.0\n",
            "soundfile                        0.12.1\n",
            "soupsieve                        2.5\n",
            "soxr                             0.3.7\n",
            "spacy                            3.6.1\n",
            "spacy-legacy                     3.0.12\n",
            "spacy-loggers                    1.0.5\n",
            "Sphinx                           5.0.2\n",
            "sphinxcontrib-applehelp          1.0.7\n",
            "sphinxcontrib-devhelp            1.0.5\n",
            "sphinxcontrib-htmlhelp           2.0.4\n",
            "sphinxcontrib-jsmath             1.0.1\n",
            "sphinxcontrib-qthelp             1.0.6\n",
            "sphinxcontrib-serializinghtml    1.1.9\n",
            "SQLAlchemy                       2.0.23\n",
            "sqlglot                          17.16.2\n",
            "sqlparse                         0.4.4\n",
            "srsly                            2.4.8\n",
            "stanio                           0.3.0\n",
            "statsmodels                      0.14.0\n",
            "sympy                            1.12\n",
            "tables                           3.8.0\n",
            "tabulate                         0.9.0\n",
            "tbb                              2021.11.0\n",
            "tblib                            3.0.0\n",
            "tenacity                         8.2.3\n",
            "tensorboard                      2.14.1\n",
            "tensorboard-data-server          0.7.2\n",
            "tensorflow                       2.14.0\n",
            "tensorflow-datasets              4.9.3\n",
            "tensorflow-estimator             2.14.0\n",
            "tensorflow-gcs-config            2.14.0\n",
            "tensorflow-hub                   0.15.0\n",
            "tensorflow-io-gcs-filesystem     0.34.0\n",
            "tensorflow-metadata              1.14.0\n",
            "tensorflow-probability           0.22.0\n",
            "tensorstore                      0.1.45\n",
            "termcolor                        2.4.0\n",
            "terminado                        0.18.0\n",
            "text-unidecode                   1.3\n",
            "textblob                         0.17.1\n",
            "tf-slim                          1.1.0\n",
            "thinc                            8.1.12\n",
            "threadpoolctl                    3.2.0\n",
            "tifffile                         2023.9.26\n",
            "tiktoken                         0.5.2\n",
            "tinycss2                         1.2.1\n",
            "tokenizers                       0.15.0\n",
            "toml                             0.10.2\n",
            "tomli                            2.0.1\n",
            "toolz                            0.12.0\n",
            "torch                            2.1.0+cu118\n",
            "torchaudio                       2.1.0+cu118\n",
            "torchdata                        0.7.0\n",
            "torchsummary                     1.5.1\n",
            "torchtext                        0.16.0\n",
            "torchvision                      0.16.0+cu118\n",
            "tornado                          6.3.2\n",
            "tqdm                             4.66.1\n",
            "traitlets                        5.7.1\n",
            "traittypes                       0.2.1\n",
            "transformers                     4.35.2\n",
            "triton                           2.1.0\n",
            "tweepy                           4.14.0\n",
            "typer                            0.9.0\n",
            "types-pytz                       2023.3.1.1\n",
            "types-setuptools                 69.0.0.0\n",
            "typing_extensions                4.5.0\n",
            "typing-inspect                   0.9.0\n",
            "tzlocal                          5.2\n",
            "uc-micro-py                      1.0.2\n",
            "uritemplate                      4.1.1\n",
            "urllib3                          2.0.7\n",
            "vega-datasets                    0.9.0\n",
            "wadllib                          1.3.6\n",
            "wasabi                           1.1.2\n",
            "wcwidth                          0.2.12\n",
            "webcolors                        1.13\n",
            "webencodings                     0.5.1\n",
            "websocket-client                 1.7.0\n",
            "Werkzeug                         3.0.1\n",
            "wheel                            0.42.0\n",
            "widgetsnbextension               3.6.6\n",
            "wordcloud                        1.9.2\n",
            "wrapt                            1.14.1\n",
            "xarray                           2023.7.0\n",
            "xarray-einstats                  0.6.0\n",
            "xgboost                          2.0.2\n",
            "xlrd                             2.0.1\n",
            "xxhash                           3.4.1\n",
            "xyzservices                      2023.10.1\n",
            "yarl                             1.9.3\n",
            "yellowbrick                      1.5\n",
            "yfinance                         0.2.32\n",
            "zict                             3.0.0\n",
            "zipp                             3.17.0\n"
          ]
        }
      ],
      "source": [
        "!pip list"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyNGFRtEzF+pmpVnazWF2eIb",
      "collapsed_sections": [
        "mtGKUVg3wI0d"
      ],
      "include_colab_link": true,
      "provenance": []
    },
    "kernelspec": {
      "display_name": "data-science-project-VmJyb5kE-py3.11",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
